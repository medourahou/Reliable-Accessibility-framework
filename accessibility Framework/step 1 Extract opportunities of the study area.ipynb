{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5057ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medourahou1/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "from typing import Dict, Optional,List, Tuple\n",
    "\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from typing import Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850e306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_osm_bbox(\n",
    "    df: pd.DataFrame,\n",
    "    from_epsg: int = 32632,\n",
    "    buffer_percent: float = 0.01,\n",
    "    transform_coords: bool = True\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate a bounding box (bbox) for OpenStreetMap (OSM) queries from a DataFrame containing SMS trips'\n",
    "    latitude and longitude coordinates, with an optional buffer zone.\n",
    "\n",
    "    The function processes departure and arrival coordinates to find the minimum and maximum\n",
    "    extents, adds a buffer zone, and returns the bbox in a format suitable for OSM queries.\n",
    "    The coordinates are expected to be in the specified EPSG coordinate system.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the following columns:\n",
    "        - departure_longitude: Longitude coordinates of departure points\n",
    "        - departure_latitude: Latitude coordinates of departure points\n",
    "        - arrival_longitude: Longitude coordinates of arrival points\n",
    "        - arrival_latitude: Latitude coordinates of arrival points\n",
    "        All coordinates should be in the specified input coordinate system (from_epsg)\n",
    "\n",
    "    from_epsg : int, optional\n",
    "        EPSG code of the input coordinate system (default: 32632 for UTM zone 32N)\n",
    "        Common values:\n",
    "        - 32632: UTM zone 32N\n",
    "        - 4326: WGS84 (standard GPS coordinates)\n",
    "\n",
    "    buffer_percent : float, optional\n",
    "        Percentage of the coordinate range to add as buffer (default: 0.01 for 1%)\n",
    "        Must be between 0 and 1\n",
    "\n",
    "    transform_coords : bool, optional\n",
    "        Whether to transform coordinates from input EPSG to WGS84 (default: True)\n",
    "        Set to False if coordinates are already in WGS84\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing the bounding box coordinates:\n",
    "        - min_lat: Minimum latitude (southern boundary)\n",
    "        - max_lat: Maximum latitude (northern boundary)\n",
    "        - min_lon: Minimum longitude (western boundary)\n",
    "        - max_lon: Maximum longitude (eastern boundary)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If required columns are missing from DataFrame\n",
    "        If buffer_percent is not between 0 and 1\n",
    "        If coordinates are outside valid ranges\n",
    "        If DataFrame is empty\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'departure_longitude': [10.0, 10.5],\n",
    "    ...     'departure_latitude': [50.0, 50.5],\n",
    "    ...     'arrival_longitude': [11.0, 11.5],\n",
    "    ...     'arrival_latitude': [51.0, 51.5]\n",
    "    ... })\n",
    "    >>> bbox = get_osm_bbox(df, from_epsg=4326)\n",
    "    >>> print(bbox)\n",
    "    {\n",
    "        'min_lat': 49.95,\n",
    "        'max_lat': 51.55,\n",
    "        'min_lon': 9.95,\n",
    "        'max_lon': 11.55\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Validate input parameters\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty\")\n",
    "\n",
    "    required_columns = [\n",
    "        'departure_longitude', 'departure_latitude',\n",
    "        'arrival_longitude', 'arrival_latitude'\n",
    "    ]\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    if not 0 <= buffer_percent <= 1:\n",
    "        raise ValueError(\"buffer_percent must be between 0 and 1\")\n",
    "\n",
    "    # Create transformer if needed\n",
    "    if transform_coords:\n",
    "        transformer = Transformer.from_crs(f\"EPSG:{from_epsg}\", \"EPSG:4326\", always_xy=True)\n",
    "    \n",
    "    # Get all x and y coordinates\n",
    "    x_coords = np.concatenate([\n",
    "        df['departure_longitude'].values,\n",
    "        df['arrival_longitude'].values\n",
    "    ])\n",
    "    y_coords = np.concatenate([\n",
    "        df['departure_latitude'].values,\n",
    "        df['arrival_latitude'].values\n",
    "    ])\n",
    "    \n",
    "    # Check for invalid coordinates\n",
    "    if transform_coords:\n",
    "        # For projected coordinates, checks will depend on the specific projection\n",
    "        pass\n",
    "    else:\n",
    "        # For WGS84, check latitude and longitude ranges\n",
    "        if not (-180 <= x_coords).all() or not (x_coords <= 180).all():\n",
    "            raise ValueError(\"Longitude values must be between -180 and 180 degrees\")\n",
    "        if not (-90 <= y_coords).all() or not (y_coords <= 90).all():\n",
    "            raise ValueError(\"Latitude values must be between -90 and 90 degrees\")\n",
    "    \n",
    "    # Calculate bbox\n",
    "    min_x = np.min(x_coords)\n",
    "    max_x = np.max(x_coords)\n",
    "    min_y = np.min(y_coords)\n",
    "    max_y = np.max(y_coords)\n",
    "    \n",
    "    # Add buffer\n",
    "    x_buffer = (max_x - min_x) * buffer_percent\n",
    "    y_buffer = (max_y - min_y) * buffer_percent\n",
    "    \n",
    "    min_x -= x_buffer\n",
    "    max_x += x_buffer\n",
    "    min_y -= y_buffer\n",
    "    max_y += y_buffer\n",
    "    \n",
    "    # Transform coordinates if needed\n",
    "    if transform_coords:\n",
    "        min_x, min_y = transformer.transform(min_x, min_y)\n",
    "        max_x, max_y = transformer.transform(max_x, max_y)\n",
    "    \n",
    "    # Ensure transformed coordinates are within valid ranges for WGS84\n",
    "    min_x = max(-180, min(180, min_x))\n",
    "    max_x = max(-180, min(180, max_x))\n",
    "    min_y = max(-90, min(90, min_y))\n",
    "    max_y = max(-90, min(90, max_y))\n",
    "    \n",
    "    # Create bbox dict\n",
    "    bbox_dict = {\n",
    "        'min_lat': min_y,\n",
    "        'max_lat': max_y,\n",
    "        'min_lon': min_x,\n",
    "        'max_lon': max_x\n",
    "    }\n",
    "    \n",
    "    return bbox_dict\n",
    "\n",
    "\n",
    "def validate_bbox(bbox: Dict[str, float]) -> bool:\n",
    "    \"\"\"\n",
    "    Validate a bounding box dictionary to ensure coordinates are within valid ranges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox : dict\n",
    "        Dictionary containing min_lat, max_lat, min_lon, max_lon keys\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if bbox is valid, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if all required keys exist\n",
    "        required_keys = ['min_lat', 'max_lat', 'min_lon', 'max_lon']\n",
    "        if not all(key in bbox for key in required_keys):\n",
    "            return False\n",
    "        \n",
    "        # Check latitude ranges\n",
    "        if not (-90 <= bbox['min_lat'] <= bbox['max_lat'] <= 90):\n",
    "            return False\n",
    "        \n",
    "        # Check longitude ranges\n",
    "        if not (-180 <= bbox['min_lon'] <= bbox['max_lon'] <= 180):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    except (KeyError, TypeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7607b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_input_path = \"SMS_trips.csv\"\n",
    "trips= pd.read_csv(legs_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff42b69-16c8-43c0-8b21-286bffeb351a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_lat': 48.85222597,\n",
       " 'max_lat': 48.92658703,\n",
       " 'min_lon': 1.825876142,\n",
       " 'max_lon': 2.052240458}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox= get_osm_bbox(trips)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b72c05",
   "metadata": {},
   "source": [
    "## Extract opportunities using OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8c8fd3-81c6-40f2-a6bd-63aa2a681319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1835152/3671200696.py:162: FutureWarning: The `geometries` module and `geometries_from_X` functions have been renamed the `features` module and `features_from_X` functions. Use these instead. The `geometries` module and function names are deprecated and will be removed in the v2.0.0 release. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  geo_df = ox.geometries.geometries_from_bbox(*bbox_tuple, tags)\n",
      "/home/medourahou1/.local/lib/python3.10/site-packages/osmnx/geometries.py:48: FutureWarning: The `north`, `south`, `east`, and `west` parameters are deprecated and will be removed in the v2.0.0 release. Use the `bbox` parameter instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  return features.features_from_bbox(north, south, east, west, tags=tags)\n",
      "/home/medourahou1/.local/lib/python3.10/site-packages/osmnx/geometries.py:48: FutureWarning: The expected order of coordinates in `bbox` will change in the v2.0.0 release to `(left, bottom, right, top)`.\n",
      "  return features.features_from_bbox(north, south, east, west, tags=tags)\n"
     ]
    }
   ],
   "source": [
    "# Constants for OpenStreetMap feature tags\n",
    "AMENITY_TAGS: List[str] = [\n",
    "    # Transportation\n",
    "    \"bus_stop\",\n",
    "    \"stop_position\",\n",
    "    \"platform\",\n",
    "    \"station\",\n",
    "    \"stop_area\",\n",
    "    \"stop_area_group\",\n",
    "    \"car_sharing\",\n",
    "    \n",
    "    # Education\n",
    "    \"college\",\n",
    "    \"kindergarten\",\n",
    "    \"library\",\n",
    "    \"school\",\n",
    "    \"research_institute\",\n",
    "    \n",
    "    # Healthcare\n",
    "    \"clinic\",\n",
    "    \"doctors\",\n",
    "    \"dentist\",\n",
    "    \"pharmacy\",\n",
    "    \"veterinary\",\n",
    "    \n",
    "    # Social and Community\n",
    "    \"social_facility\",\n",
    "    \"community_centre\",\n",
    "    \"social_centre\",\n",
    "    \n",
    "    # Entertainment\n",
    "    \"cinema\",\n",
    "    \"theatre\",\n",
    "    \n",
    "    # Commercial\n",
    "    \"market_place\",\n",
    "    \n",
    "    # Business/Office\n",
    "    \"office\",              \n",
    "    \"bank\",               \n",
    "    \"insurance\",          \n",
    "    \"company\",            \n",
    "    \"consulting\",         \n",
    "    \"estate_agent\",       \n",
    "    \"government\",         \n",
    "    \"lawyer\",             \n",
    "    \"tax_advisor\",        \n",
    "    \"telecommunication\",  \n",
    "    \"travel_agent\",       \n",
    "    \"coworking_space\",    \n",
    "]\n",
    "\n",
    "OFFICE_TAGS: Dict[str, List[str]] = {\n",
    "    \"office\": [\n",
    "        \"accountant\",\n",
    "        \"advertising_agency\",\n",
    "        \"architect\",\n",
    "        \"association\",\n",
    "        \"company\",\n",
    "        \"consulting\",\n",
    "        \"coworking\",\n",
    "        \"educational_institution\",\n",
    "        \"employment_agency\",\n",
    "        \"engineering\",\n",
    "        \"estate_agent\",\n",
    "        \"financial\",\n",
    "        \"foundation\",\n",
    "        \"government\",\n",
    "        \"insurance\",\n",
    "        \"it\",\n",
    "        \"lawyer\",\n",
    "        \"ngo\",\n",
    "        \"notary\",\n",
    "        \"physician\",\n",
    "        \"research\",\n",
    "        \"software\",\n",
    "        \"telecommunication\",\n",
    "        \"travel_agent\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "SHOP_TAGS: Dict[str, List[str]] = {\n",
    "    \"shop\": [\n",
    "        \"supermarket\",\n",
    "        \"department_store\",\n",
    "        \"mall\",\n",
    "        \"convenience\",\n",
    "        \"clothes\",\n",
    "        \"electronics\",\n",
    "        \"hardware\",\n",
    "        \"furniture\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "INDUSTRIAL_TAGS: Dict[str, List[str]] = {\n",
    "    \"landuse\": [\n",
    "        \"industrial\",\n",
    "        \"commercial\",\n",
    "        \"retail\",\n",
    "        \"office\",\n",
    "        \"business_park\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def fetch_osm_features(\n",
    "    bounding_box: Dict[str, float],\n",
    "    custom_tags: Dict[str, List[str]] = None\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Fetch OpenStreetMap features within a specified bounding box using OSMnx.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bounding_box : dict\n",
    "        Dictionary containing the bounding box coordinates:\n",
    "        - min_lat: Minimum latitude (south)\n",
    "        - max_lat: Maximum latitude (north)\n",
    "        - min_lon: Minimum longitude (west)\n",
    "        - max_lon: Maximum longitude (east)\n",
    "    custom_tags : dict, optional\n",
    "        Custom tags to override default tag configuration\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing the retrieved features with their geometries\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> bbox = {\n",
    "    ...     'min_lat': 48.85222597,\n",
    "    ...     'max_lat': 48.92658703,\n",
    "    ...     'min_lon': 1.825876142,\n",
    "    ...     'max_lon': 2.052240458\n",
    "    ... }\n",
    "    >>> gdf = fetch_osm_features(bbox)\n",
    "    \"\"\"\n",
    "    # Configure OSMnx settings\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.log_console = True\n",
    "    \n",
    "    # Convert bounding box to tuple format required by OSMnx\n",
    "    bbox_tuple = (\n",
    "        bounding_box['min_lat'],\n",
    "        bounding_box['max_lat'],\n",
    "        bounding_box['min_lon'],\n",
    "        bounding_box['max_lon']\n",
    "    )\n",
    "    \n",
    "    # Define default tags if custom tags not provided\n",
    "    if custom_tags is None:\n",
    "        tags = {\n",
    "            \"amenity\": AMENITY_TAGS,\n",
    "            \"office\": OFFICE_TAGS[\"office\"],\n",
    "            \"shop\": SHOP_TAGS[\"shop\"],\n",
    "            \"landuse\": INDUSTRIAL_TAGS[\"landuse\"]\n",
    "        }\n",
    "    else:\n",
    "        tags = custom_tags\n",
    "    \n",
    "    # Retrieve geographical features\n",
    "    geo_df = ox.geometries.geometries_from_bbox(*bbox_tuple, tags)\n",
    "    \n",
    "    # Convert to GeoDataFrame with specified CRS\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        geo_df,\n",
    "        geometry=geo_df['geometry'],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def save_features_shapefile(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    filename: str = \"osm_features.shp\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save a GeoDataFrame to a shapefile.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing the features to save\n",
    "    filename : str, optional\n",
    "        Name of the output shapefile (default: \"osm_features.shp\")\n",
    "    \"\"\"\n",
    "    gdf.to_file(filename)\n",
    "    print(f\"Shapefile has been saved as {filename}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the usage of the OSM feature extraction pipeline.\n",
    "    \"\"\"\n",
    "    # Define the bounding box (example for greater Paris)\n",
    "    bounding_box = {'min_lat': 48.85222597,\n",
    " 'max_lat': 48.92658703,\n",
    " 'min_lon': 1.825876142,\n",
    " 'max_lon': 2.052240458}\n",
    "    \n",
    "    # Fetch features\n",
    "    gdf = fetch_osm_features(bounding_box)\n",
    "    \n",
    "    \n",
    "    return gdf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gdf = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01058908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Analysis Before Processing:\n",
      "            Criteria  Duplicate Count\n",
      "0          Name only               81\n",
      "1      Geometry only                0\n",
      "2  Name and Geometry                0\n",
      "Successfully saved to ../Cities/Padam_terretory_01/shp files/opps_for_padam_terretory_01.shp\n",
      "\n",
      "Duplicate Analysis After Processing:\n",
      "            Criteria  Duplicate Count\n",
      "0          Name only               81\n",
      "1      Geometry only                0\n",
      "2  Name and Geometry                0\n",
      "\n",
      "Summary Statistics:\n",
      "Original features: 251\n",
      "Processed features: 251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_geodataframe(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    selected_columns: list = [\"amenity\", \"name\", \"geometry\"],\n",
    "    output_path: Optional[str] = None\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Process a GeoDataFrame by adding IDs, removing duplicates, converting polygons \n",
    "    to centroids, and optionally saving to a shapefile.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        Input GeoDataFrame containing spatial features\n",
    "    selected_columns : list, optional\n",
    "        List of columns to keep in the final DataFrame\n",
    "        Default: [\"amenity\", \"name\", \"geometry\"]\n",
    "    output_path : str, optional\n",
    "        Path to save the output shapefile\n",
    "        If None, the file won't be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        Processed GeoDataFrame with unique features and centroids\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The function performs the following operations:\n",
    "    1. Resets the index and adds sequential IDs\n",
    "    2. Removes duplicate entries based on name and geometry\n",
    "    3. Converts polygons and multipolygons to centroids\n",
    "    4. Removes LineString geometries\n",
    "    5. Adds a population field (set to 1.0)\n",
    "    \"\"\"\n",
    "    # Reset index and create sequential IDs\n",
    "    df_reset = gdf.reset_index()\n",
    "    \n",
    "    # Remove duplicates based on name and geometry\n",
    "    if 'name' in df_reset.columns:\n",
    "        df_reset = df_reset.drop_duplicates(subset=['name', 'geometry'])\n",
    "    else:\n",
    "        df_reset = df_reset.drop_duplicates(subset=['geometry'])\n",
    "    \n",
    "    # Create new sequential IDs after removing duplicates\n",
    "    df_reset['id'] = range(1, len(df_reset) + 1)\n",
    "    \n",
    "    # Select required columns\n",
    "    columns = [\"id\"] + selected_columns\n",
    "    df_reset = df_reset[columns]\n",
    "    \n",
    "    # Convert back to GeoDataFrame\n",
    "    gdf_processed = gpd.GeoDataFrame(df_reset, geometry='geometry')\n",
    "    \n",
    "    # Convert polygons/multipolygons to centroids\n",
    "    gdf_processed['geometry'] = gdf_processed['geometry'].apply(_to_centroid)\n",
    "    \n",
    "    # assign each opp a number 1 for computation after\n",
    "    gdf_processed['pop'] = 1.0\n",
    "    \n",
    "    # Remove LineString geometries\n",
    "    gdf_processed = gdf_processed[\n",
    "        gdf_processed.geometry.apply(lambda geom: geom.geom_type != 'LineString')\n",
    "    ]\n",
    "    \n",
    "    # Save to file if path is provided\n",
    "    if output_path:\n",
    "        try:\n",
    "            gdf_processed.to_file(output_path)\n",
    "            print(f\"Successfully saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file: {str(e)}\")\n",
    "    \n",
    "    return gdf_processed\n",
    "\n",
    "def _to_centroid(geometry: Union[Point, Polygon, MultiPolygon]) -> Point:\n",
    "    \"\"\"\n",
    "    Convert polygon or multipolygon geometry to its centroid.\n",
    "    Points remain unchanged.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geometry : Union[Point, Polygon, MultiPolygon]\n",
    "        Input geometry to be converted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Point\n",
    "        Centroid of the input geometry or original point\n",
    "    \"\"\"\n",
    "    if isinstance(geometry, (Polygon, MultiPolygon)):\n",
    "        return geometry.centroid\n",
    "    return geometry\n",
    "\n",
    "def analyze_duplicates(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze duplicate entries in the GeoDataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        Input GeoDataFrame to analyze\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Summary of duplicate entries\n",
    "    \"\"\"\n",
    "    # Check duplicates based on different criteria\n",
    "    name_dupes = gdf.duplicated(subset=['name'], keep=False).sum() if 'name' in gdf.columns else 0\n",
    "    geom_dupes = gdf.duplicated(subset=['geometry'], keep=False).sum()\n",
    "    both_dupes = (gdf.duplicated(subset=['name', 'geometry'], keep=False).sum() \n",
    "                 if 'name' in gdf.columns else 0)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Criteria': ['Name only', 'Geometry only', 'Name and Geometry'],\n",
    "        'Duplicate Count': [name_dupes, geom_dupes, both_dupes]\n",
    "    })\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    output_path = \"../Cities/Padam_terretory_01/shp files/opps_for_padam_terretory_01.shp\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Analyze duplicates before processing\n",
    "    print(\"Duplicate Analysis Before Processing:\")\n",
    "    print(analyze_duplicates(gdf))\n",
    "    \n",
    "    # Process the GeoDataFrame\n",
    "    processed_gdf = process_geodataframe(\n",
    "        gdf,\n",
    "        selected_columns=[\"amenity\", \"name\", \"geometry\"],\n",
    "        output_path=output_path\n",
    "    )\n",
    "    \n",
    "    # Analyze duplicates after processing\n",
    "    print(\"\\nDuplicate Analysis After Processing:\")\n",
    "    print(analyze_duplicates(processed_gdf))\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Original features: {len(gdf)}\")\n",
    "    print(f\"Processed features: {len(processed_gdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d975841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to output.shp\n",
      "            Criteria  Duplicate Count\n",
      "0          Name only               81\n",
      "1      Geometry only                0\n",
      "2  Name and Geometry                0\n"
     ]
    }
   ],
   "source": [
    "# Basic usage\n",
    "processed_gdf = process_geodataframe(gdf)\n",
    "\n",
    "# Advanced usage with custom columns and output path\n",
    "processed_gdf = process_geodataframe(\n",
    "    gdf,\n",
    "    selected_columns=[\"amenity\", \"name\", \"geometry\"],\n",
    "    output_path=\"output.shp\"\n",
    ")\n",
    "\n",
    "# Analyze duplicates in your data\n",
    "duplicate_analysis = analyze_duplicates(gdf)\n",
    "print(duplicate_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c02e492-99db-4b6b-b8b1-2f40cb2949e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amenity</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pharmacy</td>\n",
       "      <td>Pharmacie de l'Église</td>\n",
       "      <td>POINT (1.97643 48.91973)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franprix</td>\n",
       "      <td>POINT (2.05223 48.92607)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>school</td>\n",
       "      <td>École élémentaire Louis Pasteur</td>\n",
       "      <td>POINT (2.02192 48.86020)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>school</td>\n",
       "      <td>École maternelle Jean de La Fontaine</td>\n",
       "      <td>POINT (2.02285 48.86054)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1.97564 48.92002)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1.95081 48.91590)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (2.05174 48.89888)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>school</td>\n",
       "      <td>Groupe Scolaire Roger Gousseau</td>\n",
       "      <td>POINT (1.92272 48.91099)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>kindergarten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (2.02059 48.92092)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alinéa</td>\n",
       "      <td>POINT (2.03248 48.91247)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       amenity                                  name  \\\n",
       "0      1      pharmacy                 Pharmacie de l'Église   \n",
       "1      2           NaN                              Franprix   \n",
       "2      3        school       École élémentaire Louis Pasteur   \n",
       "3      4        school  École maternelle Jean de La Fontaine   \n",
       "4      5          bank                                   NaN   \n",
       "..   ...           ...                                   ...   \n",
       "246  247           NaN                                   NaN   \n",
       "247  248        school                                   NaN   \n",
       "248  249        school        Groupe Scolaire Roger Gousseau   \n",
       "249  250  kindergarten                                   NaN   \n",
       "250  251           NaN                                Alinéa   \n",
       "\n",
       "                     geometry  pop  \n",
       "0    POINT (1.97643 48.91973)  1.0  \n",
       "1    POINT (2.05223 48.92607)  1.0  \n",
       "2    POINT (2.02192 48.86020)  1.0  \n",
       "3    POINT (2.02285 48.86054)  1.0  \n",
       "4    POINT (1.97564 48.92002)  1.0  \n",
       "..                        ...  ...  \n",
       "246  POINT (1.95081 48.91590)  1.0  \n",
       "247  POINT (2.05174 48.89888)  1.0  \n",
       "248  POINT (1.92272 48.91099)  1.0  \n",
       "249  POINT (2.02059 48.92092)  1.0  \n",
       "250  POINT (2.03248 48.91247)  1.0  \n",
       "\n",
       "[251 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
