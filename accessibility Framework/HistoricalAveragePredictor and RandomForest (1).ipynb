{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d73338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medourahou1/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet, HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import random\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor,BayesianRidge\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# import pybnesian as pbn\n",
    "\n",
    "from shapely import wkt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.stats import gamma as scipy_gamma\n",
    "from scipy.special import gamma as gamma_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff73bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "legs_input_path = '../Cities/Padam_terretory_01/Ressources/cleaned_padam__drt_trips_terretory_01.csv' # MATSim output legs csv file\n",
    " \n",
    "# popArea_input_path = 'shp/CentresOfInterest_great_paris.shp' # the population of paris \n",
    "\n",
    "\n",
    "# EPSG code !!ONLY NUMBER!! EPSG:3035 --> 3035\n",
    "crs_import = 2154 #2154 # crs of the raw imported data\n",
    "crs_working = 2154 #2154 # crs used for the processing (can be same as crs_import)\n",
    "\n",
    "# Toggle for preprocessing steps\n",
    "# GTFS preprocessing to get hexagonal grid\n",
    "#      --> needed once, can be skipped if GTFScells.csv file exists\n",
    "toggle_GTFSprep = False\n",
    "GTFScells_path = '../Cities/Padam_terretory_01/Ressources/cells_of_padam_terretory_01.csv'\n",
    "\n",
    "\n",
    "# Interpolation will only be done in this time window\n",
    "start_time = '06:00:00'\n",
    "end_time = '22:00:00'\n",
    "# Length of each analysis interval (the estimation of travel time and wait time will be done for each deltaT interval)\n",
    "deltaT = 1 # in hours (h), default 1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e96546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1596638/1865277605.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.rename(columns = {   \"departure_latitude_x\" : 'departure_latitude',\n"
     ]
    }
   ],
   "source": [
    "trips_df= pd.read_csv(legs_input_path, sep=\",\")\n",
    "dataset = trips_df[['departure_latitude_x', 'departure_longitude_x', 'arrival_latitude_x',\n",
    "       'arrival_longitude_x', 'departure_time_hour',\n",
    "       'departure_time_minute', 'departure_time_seconds',\n",
    "       'departure_time_day_of_week', 'departure_time_day_of_month',\n",
    "       'departure_time_month', 'departure_time_hour_sin',\n",
    "       'departure_time_hour_cos', 'departure_time_day_of_week_sin',\n",
    "       'departure_time_day_of_week_cos', 'departure_time_month_sin',\n",
    "       'departure_time_month_cos', 'route_distance','travel_time']]\n",
    "\n",
    "dataset.rename(columns = {   \"departure_latitude_x\" : 'departure_latitude',\n",
    "                            \"departure_longitude_x\" : \"departure_longitude\",\n",
    "                            \"arrival_latitude_x\" : 'arrival_latitude',\n",
    "                            \"arrival_longitude_x\" : 'arrival_longitude'\n",
    "                        \n",
    "                          },inplace=True)\n",
    "\n",
    "dataset2 = dataset[dataset[\"travel_time\"]<=2500]\n",
    "dataset3 =dataset2[dataset2[\"travel_time\"]>=60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e2cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset3[['departure_latitude', 'departure_longitude', 'arrival_latitude',\n",
    "       'arrival_longitude', 'departure_time_hour','departure_time_day_of_week',\n",
    "       'departure_time_day_of_month', 'departure_time_month','route_distance', 'travel_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109ee6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize models\\nhist_avg_model = HistoricalAveragePredictor(segment_by_time=True)\\nrf_model = RandomForestTravelTimePredictor(n_estimators=100)\\n\\n# Train models\\nhist_avg_model.fit(train_df)\\nrf_model.fit(train_df)\\n\\n# Evaluate models\\nhist_results = hist_avg_model.evaluate(test_df)\\nrf_results = rf_model.evaluate(test_df)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import scipy.stats\n",
    "\n",
    "class HistoricalAveragePredictor:\n",
    "    def __init__(self, segment_by_time=True):\n",
    "        self.segment_by_time = segment_by_time\n",
    "        self.route_means = {}\n",
    "        self.route_time_means = {}\n",
    "        \n",
    "    def create_route_key(self, row):\n",
    "        \"\"\"Create a unique key for each route based on departure and arrival coordinates\"\"\"\n",
    "        return f\"{row['departure_latitude']:.4f}_{row['departure_longitude']:.4f}_\" + \\\n",
    "               f\"{row['arrival_latitude']:.4f}_{row['arrival_longitude']:.4f}\"\n",
    "    \n",
    "    def create_time_key(self, row):\n",
    "        \"\"\"Create a time segment key based on hour and day of week\"\"\"\n",
    "        return f\"{row['departure_time_day_of_week']}_{row['departure_time_hour']}\"\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        \"\"\"Calculate historical averages for each route and time segment\"\"\"\n",
    "        # Calculate route-level means\n",
    "        for _, row in train_df.iterrows():\n",
    "            route_key = self.create_route_key(row)\n",
    "            if self.segment_by_time:\n",
    "                time_key = self.create_time_key(row)\n",
    "                full_key = f\"{route_key}_{time_key}\"\n",
    "                \n",
    "                if full_key not in self.route_time_means:\n",
    "                    self.route_time_means[full_key] = []\n",
    "                self.route_time_means[full_key].append(row['travel_time'])\n",
    "            \n",
    "            if route_key not in self.route_means:\n",
    "                self.route_means[route_key] = []\n",
    "            self.route_means[route_key].append(row['travel_time'])\n",
    "        \n",
    "        # Convert lists to means\n",
    "        self.route_means = {k: np.mean(v) for k, v in self.route_means.items()}\n",
    "        if self.segment_by_time:\n",
    "            self.route_time_means = {k: np.mean(v) for k, v in self.route_time_means.items()}\n",
    "        \n",
    "        # Calculate global mean for unknown routes\n",
    "        self.global_mean = train_df['travel_time'].mean()\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"Predict travel times using historical averages\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for _, row in test_df.iterrows():\n",
    "            route_key = self.create_route_key(row)\n",
    "            \n",
    "            if self.segment_by_time:\n",
    "                time_key = self.create_time_key(row)\n",
    "                full_key = f\"{route_key}_{time_key}\"\n",
    "                \n",
    "                if full_key in self.route_time_means:\n",
    "                    predictions.append(self.route_time_means[full_key])\n",
    "                elif route_key in self.route_means:\n",
    "                    predictions.append(self.route_means[route_key])\n",
    "                else:\n",
    "                    predictions.append(self.global_mean)\n",
    "            else:\n",
    "                predictions.append(self.route_means.get(route_key, self.global_mean))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def evaluate(self, test_df):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        predictions = self.predict(test_df)\n",
    "        actual = test_df['travel_time'].values\n",
    "        \n",
    "        mae = mean_absolute_error(actual, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "        mape = np.mean(np.abs((actual - predictions) / actual)) * 100\n",
    "        r2 = r2_score(actual, predictions)\n",
    "        \n",
    "        print(f\"Historical Average Model Performance:\")\n",
    "        print(f\"MAE: {mae:.2f} seconds\")\n",
    "        print(f\"RMSE: {rmse:.2f} seconds\")\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "\n",
    "class RandomForestTravelTimePredictor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, random_state=42):\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1  # Use all available cores\n",
    "        )\n",
    "        self.base_features = [\n",
    "            'departure_latitude', 'departure_longitude',\n",
    "            'arrival_latitude', 'arrival_longitude',\n",
    "            'departure_time_hour', 'departure_time_day_of_week',\n",
    "            'departure_time_day_of_month', 'departure_time_month',\n",
    "            'route_distance'\n",
    "        ]\n",
    "    \n",
    "    def add_cyclic_features(self, df):\n",
    "        \"\"\"Add cyclic time features to the dataframe\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Hour features (24-hour cycle)\n",
    "        df['departure_time_hour_sin'] = np.sin(2 * np.pi * df['departure_time_hour'] / 24)\n",
    "        df['departure_time_hour_cos'] = np.cos(2 * np.pi * df['departure_time_hour'] / 24)\n",
    "        \n",
    "        # Day of week features (7-day cycle)\n",
    "        df['departure_time_day_of_week_sin'] = np.sin(2 * np.pi * df['departure_time_day_of_week'] / 7)\n",
    "        df['departure_time_day_of_week_cos'] = np.cos(2 * np.pi * df['departure_time_day_of_week'] / 7)\n",
    "        \n",
    "        # Month features (12-month cycle)\n",
    "        df['departure_time_month_sin'] = np.sin(2 * np.pi * df['departure_time_month'] / 12)\n",
    "        df['departure_time_month_cos'] = np.cos(2 * np.pi * df['departure_time_month'] / 12)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        \"\"\"Prepare features for the model\"\"\"\n",
    "        # Add cyclic features\n",
    "        df = self.add_cyclic_features(df)\n",
    "        \n",
    "        # Combine base features with cyclic features\n",
    "        all_features = self.base_features + [\n",
    "            'departure_time_hour_sin', 'departure_time_hour_cos',\n",
    "            'departure_time_day_of_week_sin', 'departure_time_day_of_week_cos',\n",
    "            'departure_time_month_sin', 'departure_time_month_cos'\n",
    "        ]\n",
    "        \n",
    "        # Extract features and handle missing values\n",
    "        features = df[all_features].values\n",
    "        features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return features\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        \"\"\"Train the Random Forest model\"\"\"\n",
    "        X_train = self.prepare_data(train_df)\n",
    "        y_train = train_df['travel_time'].values\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate feature importance\n",
    "        all_features = self.base_features + [\n",
    "            'departure_time_hour_sin', 'departure_time_hour_cos',\n",
    "            'departure_time_day_of_week_sin', 'departure_time_day_of_week_cos',\n",
    "            'departure_time_month_sin', 'departure_time_month_cos'\n",
    "        ]\n",
    "        \n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'feature': all_features,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"Make predictions using the Random Forest model\"\"\"\n",
    "        X_test = self.prepare_data(test_df)\n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, test_df):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        predictions = self.predict(test_df)\n",
    "        actual = test_df['travel_time'].values\n",
    "        \n",
    "        mae = mean_absolute_error(actual, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "        mape = np.mean(np.abs((actual - predictions) / actual)) * 100\n",
    "        r2 = r2_score(actual, predictions)\n",
    "        \n",
    "        # Calculate prediction intervals using quantile regression forest\n",
    "        tree_predictions = np.array([tree.predict(self.prepare_data(test_df)) \n",
    "                                   for tree in self.model.estimators_])\n",
    "        lower_bounds = np.percentile(tree_predictions, 2.5, axis=0)\n",
    "        upper_bounds = np.percentile(tree_predictions, 97.5, axis=0)\n",
    "        \n",
    "        print(f\"Random Forest Model Performance:\")\n",
    "        print(f\"MAE: {mae:.2f} seconds\")\n",
    "        print(f\"RMSE: {rmse:.2f} seconds\")\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        \n",
    "        print(\"\\nTop 5 Most Important Features:\")\n",
    "        print(self.feature_importance.head())\n",
    "        \n",
    "        return {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'predictions': predictions,\n",
    "            'lower_bounds': lower_bounds,\n",
    "            'upper_bounds': upper_bounds,\n",
    "            'feature_importance': self.feature_importance\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Initialize models\n",
    "hist_avg_model = HistoricalAveragePredictor(segment_by_time=True)\n",
    "rf_model = RandomForestTravelTimePredictor(n_estimators=100)\n",
    "\n",
    "# Train models\n",
    "hist_avg_model.fit(train_df)\n",
    "rf_model.fit(train_df)\n",
    "\n",
    "# Evaluate models\n",
    "hist_results = hist_avg_model.evaluate(test_df)\n",
    "rf_results = rf_model.evaluate(test_df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4383969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Average Model Performance:\n",
      "MAE: 191.53 seconds\n",
      "RMSE: 279.82 seconds\n",
      "MAPE: 32.55%\n",
      "R² Score: 0.5332\n",
      "Random Forest Model Performance:\n",
      "MAE: 188.87 seconds\n",
      "RMSE: 270.48 seconds\n",
      "MAPE: 32.85%\n",
      "R² Score: 0.5638\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "                        feature  importance\n",
      "8                route_distance    0.577868\n",
      "6   departure_time_day_of_month    0.116595\n",
      "7          departure_time_month    0.030580\n",
      "13     departure_time_month_sin    0.028074\n",
      "14     departure_time_month_cos    0.027435\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(dataset3, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "hist_avg_model = HistoricalAveragePredictor(segment_by_time=True)\n",
    "rf_model = RandomForestTravelTimePredictor(n_estimators=100)\n",
    "\n",
    "# Train models\n",
    "hist_avg_model.fit(train_data)\n",
    "rf_model.fit(train_data)\n",
    "\n",
    "# Evaluate models\n",
    "hist_results = hist_avg_model.evaluate(test_data)\n",
    "rf_results = rf_model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df099238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdf73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
